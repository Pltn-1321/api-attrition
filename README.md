# API Attrition

API FastAPI pour la prÃ©diction d'attrition des employÃ©s avec machine learning.

**Stack** : FastAPI Â· PostgreSQL/SQLite Â· SQLAlchemy Â· Streamlit Â· Scikit-learn Â· Docker

**DÃ©ploiement** : GitHub Actions Â· Hugging Face Spaces Â· CI/CD

## DÃ©marrage Rapide

```bash
# 1. Cloner et installer
git clone git@github.com:Pltn-1321/api-attrition.git
cd api-attrition
uv add pandas sqlalchemy psycopg2-binary fastapi uvicorn streamlit

# 2. DÃ©marrer PostgreSQL
docker-compose up -d

# 3. Importer les donnÃ©es (294 employÃ©s)
uv run database/import_data.py

# 4. Lancer l'application (API + Interface)
uv run streamlit_launcher.py
```

**URLs** :
- Interface : http://localhost:8501
- API : http://localhost:8000
- Docs API : http://localhost:8000/docs

## Commandes

### Lancer l'application

```bash
# Tout en un (recommandÃ©) - Lance API + Interface
uv run streamlit_launcher.py

# Ou avec le script interactif
./start.sh

# Ou sÃ©parÃ©ment
uv run uvicorn main:app --reload --port 8000  # API seulement
cd streamlit_app && uv run streamlit run app.py  # Interface seulement
```

### ArrÃªter l'application

```bash
# Avec Ctrl+C si lancÃ© avec streamlit_launcher.py
# Ou tuer les processus
lsof -ti:8000,8501 | xargs kill -9
```

### Commandes PostgreSQL

```bash
docker-compose up -d              # DÃ©marrer
docker-compose down               # ArrÃªter
docker logs attrition_db          # Voir les logs

# AccÃ©der Ã  psql
docker exec -it attrition_db psql -U attrition_user -d attrition_db
```

## API Endpoints

| Endpoint | MÃ©thode | Description |
|----------|---------|-------------|
| `/` | GET | Informations de l'API |
| `/health` | GET | VÃ©rification de santÃ© (API + DB) |
| `/employees` | GET | Liste des employÃ©s (pagination : `?skip=0&limit=100`) |
| `/employees/{id}` | GET | DÃ©tails d'un employÃ© |

**Exemples** :
```bash
curl http://localhost:8000/health
curl http://localhost:8000/employees?limit=10
curl http://localhost:8000/employees/1
```

Documentation interactive : http://localhost:8000/docs

## DonnÃ©es

**294 employÃ©s Â· 34 colonnes**

CatÃ©gories : DÃ©mographie Â· CarriÃ¨re Â· RÃ©munÃ©ration Â· Satisfaction Â· Formation Â· Indicateurs de risque

<details>
<summary>Voir toutes les colonnes</summary>

**Profil** : `id`, `genre`, `age`, `statut_marital`, `ayant_enfants`, `niveau_education`

**Professionnel** : `poste`, `departement`, `domaine_etude`, `niveau_hierarchique_poste`, `nombre_experiences_precedentes`, `annee_experience_totale`, `annees_dans_l_entreprise`, `annees_dans_le_poste_actuel`, `annees_depuis_la_derniere_promotion`, `annes_sous_responsable_actuel`, `nombre_employee_sous_responsabilite`

**Travail** : `revenu_mensuel`, `heure_supplementaires`, `nombre_heures_travailless`, `distance_domicile_travail`, `distance_categorie`, `frequence_deplacement`

**Satisfaction** : `satisfaction_employee_environnement`, `satisfaction_employee_nature_travail`, `satisfaction_employee_equipe`, `satisfaction_employee_equilibre_pro_perso`, `satisfaction_moyenne`, `note_evaluation_precedente`, `note_evaluation_actuelle`

**DÃ©veloppement** : `nb_formations_suivies`, `nombre_participation_pee`

**Risques** : `parent_burnout`, `sous_paye_niveau_dept`, `augementation_salaire_precedente`
</details>

## Interface Streamlit

Interface web interactive avec 3 pages :
- **Explorer** : Liste des employÃ©s avec filtres
- **Recherche** : DÃ©tails par ID
- **Statistiques** : Visualisations interactives (Plotly)

Voir [streamlit_app/DOCUMENTATION.md](streamlit_app/DOCUMENTATION.md) pour plus de dÃ©tails.

## Structure du Projet

```
api-attrition/
â”œâ”€â”€ main.py                     # API FastAPI
â”œâ”€â”€ streamlit_launcher.py       # Launcher API + Interface
â”œâ”€â”€ database/                   # Config DB + modÃ¨les SQLAlchemy
â”œâ”€â”€ api/                        # SchÃ©mas Pydantic
â”œâ”€â”€ streamlit_app/              # Interface Streamlit
â”‚   â”œâ”€â”€ app.py                  # Page d'accueil
â”‚   â”œâ”€â”€ pages/                  # Pages multi-pages
â”‚   â””â”€â”€ utils/                  # Client API + composants UI
â””â”€â”€ data/                       # Dataset CSV (294 employÃ©s)
```

## ðŸš€ DÃ©ploiement sur Hugging Face Spaces

L'application est automatiquement dÃ©ployÃ©e sur HF Spaces via GitHub Actions.

### Configuration (premiÃ¨re fois)

1. **CrÃ©er un token Hugging Face**
   - Allez sur https://huggingface.co/settings/tokens
   - CrÃ©ez un token avec permission **Write**
   - Copiez le token (format: `hf_xxxxxxxxxxxxx`)

2. **Ajouter le token dans GitHub Secrets**
   - Allez dans Settings â†’ Secrets and variables â†’ Actions
   - CrÃ©ez un secret `HF_TOKEN` avec votre token

3. **Pusher sur main**
   ```bash
   git push origin main
   ```

Le dÃ©ploiement se fait automatiquement ! ðŸŽ‰

**URL du Space** : https://huggingface.co/spaces/ppluton/api_technova

Voir [.github/DEPLOYMENT.md](.github/DEPLOYMENT.md) pour la documentation complÃ¨te.

### Base de donnÃ©es : PostgreSQL vs SQLite

L'application supporte deux types de bases de donnÃ©es :

**PostgreSQL** (dÃ©veloppement local avec Docker) :
```bash
export DB_TYPE=postgres  # ou ne rien dÃ©finir avec Docker
docker-compose up -d
uv run database/import_data.py
```

**SQLite** (production HF Spaces / dÃ©veloppement simple) :
```bash
export DB_TYPE=sqlite  # par dÃ©faut
uv run database/migrate_to_sqlite.py  # GÃ©nÃ¨re database.db
```

La base SQLite (`database.db`) est automatiquement crÃ©Ã©e et incluse dans le repo pour HF Spaces.

## Roadmap

- [x] ~~DÃ©ploiement cloud (Hugging Face Spaces)~~ âœ…
- [x] ~~Support SQLite pour dÃ©ploiement cloud~~ âœ…
- [x] ~~CI/CD automatique vers HF Spaces~~ âœ…
- [ ] ModÃ¨le ML pour prÃ©diction d'attrition
- [ ] Endpoint POST /predict
- [ ] Filtres avancÃ©s sur GET /employees
- [ ] Authentification API (JWT)

## Tests & CI/CD

```bash
# Lancer tous les tests
pytest

# Tests unitaires (8 tests)
pytest streamlit_app/tests/unit -v

# Tests fonctionnels (5 tests)
pytest streamlit_app/tests/functional -v

# Avec coverage
pytest streamlit_app/tests --cov=streamlit_app/utils
```

**Documentation complÃ¨te** : [CI-CD.md](CI-CD.md) - Architecture, stratÃ©gie de tests, pipeline GitHub Actions
