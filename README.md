---
title: API Technova - Gestion RH & Attrition
emoji: ğŸ‘¥
colorFrom: blue
colorTo: purple
sdk: docker
app_port: 7860
pinned: false
license: mit
tags:
  - rh
  - data-science
  - analytics
  - fastapi
  - streamlit
---

# API Attrition

[![codecov](https://codecov.io/gh/Pltn-1321/api-attrition/branch/main/graph/badge.svg)](https://codecov.io/gh/Pltn-1321/api-attrition)
[![CI/CD](https://github.com/Pltn-1321/api-attrition/workflows/CI/CD%20Pipeline/badge.svg)](https://github.com/Pltn-1321/api-attrition/actions)

API FastAPI pour la prÃ©diction d'attrition des employÃ©s avec machine learning.

**Stack** : FastAPI Â· PostgreSQL/SQLite Â· SQLAlchemy Â· Streamlit Â· Scikit-learn Â· Docker

**DÃ©ploiement** : GitHub Actions Â· Hugging Face Spaces Â· CI/CD

## DÃ©marrage Rapide

```bash
# 1. Cloner et installer
git clone git@github.com:Pltn-1321/api-attrition.git
cd api-attrition
uv add pandas sqlalchemy psycopg2-binary fastapi uvicorn streamlit

# 2. DÃ©marrer PostgreSQL
docker-compose up -d

# 3. Importer les donnÃ©es (294 employÃ©s)
uv run database/import_data.py

# 4. Lancer l'application (API + Interface)
uv run streamlit_launcher.py
```

**URLs** :
- Interface : http://localhost:8501
- API : http://localhost:8000
- Docs API : http://localhost:8000/docs

## ğŸ§ª Tests

### Structure des Tests
```
tests/
â”œâ”€â”€ unit/                    # Tests unitaires (logique isolÃ©e)
â”‚   â””â”€â”€ test_ml_model.py    # Tests modÃ¨le ML et calculs
â”œâ”€â”€ functional/             # Tests fonctionnels (scÃ©narios complets)
â”‚   â””â”€â”€ test_prediction_api.py  # Tests endpoint /predict
â”œâ”€â”€ conftest.py            # Fixtures partagÃ©es
â””â”€â”€ fixtures/              # DonnÃ©es de test
```

### ExÃ©cuter les Tests

```bash
# Tous les tests avec couverture
uv run pytest

# Tests unitaires uniquement
uv run pytest tests/unit/ -v

# Tests fonctionnels uniquement
uv run pytest tests/functional/ -v

# Tests ML spÃ©cifiques
uv run pytest tests/unit/test_ml_model.py -v --ml

# Tests API
uv run pytest tests/functional/test_prediction_api.py -v --api

# Rapport de couverture HTML
uv run pytest --cov=utils --cov=api --cov-report=html
```

### Types de Tests

#### ğŸ¤– Tests Machine Learning
- **Chargement du modÃ¨le** : VÃ©rifie que `attrition_model.joblib` se charge correctement
- **PrÃ©dictions** : Teste la cohÃ©rence des rÃ©sultats (0/1, probabilitÃ©s)
- **Cas limites** : Gestion des valeurs extrÃªmes et donnÃ©es manquantes
- **Performance** : Temps de rÃ©ponse < 100ms par prÃ©diction

#### ğŸ”Œ Tests API
- **Endpoint `/predict`** : Validation des schÃ©mas et rÃ©ponses
- **Gestion d'erreurs** : ModÃ¨le indisponible, donnÃ©es invalides
- **Concurrence** : RequÃªtes simultanÃ©es sans conflit
- **Robustesse** : CaractÃ¨res spÃ©ciaux, types de donnÃ©es

#### ğŸ“Š Couverture Cible
- **API endpoints** : 100%
- **Logique mÃ©tier** : 95%
- **ModÃ¨le ML** : 90%
- **Components UI** : 85%

### Fixtures de Test

- `sample_employee_data_low_risk` : Profil employÃ© faible risque
- `sample_employee_data_high_risk` : Profil employÃ© haut risque
- `sample_employee_data_medium_risk` : Profil employÃ© risque moyen
- `ml_model` : ModÃ¨le ML chargÃ© pour les tests

### CI/CD Integration

Les tests s'exÃ©cutent automatiquement sur :
- **Push** vers `main`/`dev`
- **Pull Requests**
- **Workflow manuel**

Le pipeline gÃ©nÃ¨re :
- Rapports de couverture Codecov
- Artefacts HTML de couverture
- Validation qualitÃ© (Ruff, Black)

## Commandes

### Lancer l'application

```bash
# Tout en un (recommandÃ©) - Lance API + Interface
uv run streamlit_launcher.py

# Ou avec le script interactif
./start.sh

# Ou sÃ©parÃ©ment
uv run uvicorn main:app --reload --port 8000  # API seulement
uv run streamlit run app.py  # Interface seulement
```

### ArrÃªter l'application

```bash
# Avec Ctrl+C si lancÃ© avec streamlit_launcher.py
# Ou tuer les processus
lsof -ti:8000,8501 | xargs kill -9
```

### Commandes PostgreSQL

```bash
docker-compose up -d              # DÃ©marrer
docker-compose down               # ArrÃªter
docker logs attrition_db          # Voir les logs

# AccÃ©der Ã  psql
docker exec -it attrition_db psql -U attrition_user -d attrition_db
```

## API Endpoints

| Endpoint | MÃ©thode | Description |
|----------|---------|-------------|
| `/` | GET | Informations de l'API |
| `/health` | GET | VÃ©rification de santÃ© (API + DB) |
| `/employees` | GET | Liste des employÃ©s (pagination : `?skip=0&limit=100`) |
| `/employees/{id}` | GET | DÃ©tails d'un employÃ© |

**Exemples** :
```bash
curl http://localhost:8000/health
curl http://localhost:8000/employees?limit=10
curl http://localhost:8000/employees/1
```

Documentation interactive : http://localhost:8000/docs

## Architecture Technique

### Infrastructure de Production (Hugging Face Spaces)

L'application utilise une architecture **monolithique conteneurisÃ©e** oÃ¹ FastAPI et Streamlit s'exÃ©cutent dans un seul conteneur Docker :

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Conteneur Docker (HF Spaces)      â”‚
â”‚                                     â”‚
â”‚  FastAPI (port 8000) â”€â”€â”€â”€â”€â”€â”       â”‚
â”‚       â†‘                     â”‚       â”‚
â”‚       â”‚ localhost:8000      â”‚       â”‚
â”‚       â”‚                     â†“       â”‚
â”‚  Streamlit (port 7860) â†’ Internet  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Points importants** :
- âœ… `API_URL=http://localhost:8000` est **correct** pour la production
- âœ… Les deux processus communiquent via localhost interne
- âœ… Seul le port 7860 (Streamlit) est exposÃ© Ã  Internet
- âœ… L'API dÃ©marre en premier, Streamlit attend qu'elle soit prÃªte (max 30s)

### SÃ©quence de DÃ©marrage

1. **Lancement du conteneur Docker** (`Dockerfile`)
2. **DÃ©marrage FastAPI** sur port 8000 (interne)
3. **VÃ©rification santÃ©** : Polling de `/health` toutes les 1s (max 30s)
4. **DÃ©marrage Streamlit** sur port 7860 (public)

Cette sÃ©quence Ã©vite l'erreur 503 "Service Unavailable" en garantissant que l'API est prÃªte avant que Streamlit essaie de s'y connecter.

### Variables d'Environnement

| Variable | Valeur par dÃ©faut | Usage |
|----------|-------------------|-------|
| `API_URL` | `http://localhost:8000` | URL de connexion Streamlitâ†’API |
| `DB_TYPE` | `sqlite` | Type de BDD (`sqlite` ou `postgres`) |
| `STREAMLIT_SERVER_PORT` | `8501` (local) / `7860` (HF) | Port d'Ã©coute Streamlit |

**Configuration automatique** :
- Le `Dockerfile` dÃ©finit `ENV API_URL=http://localhost:8000`
- La CI/CD valide que cette configuration est correcte avant dÃ©ploiement
- Les tests unitaires vÃ©rifient que `config.py` respecte ces valeurs

## DonnÃ©es

**294 employÃ©s Â· 34 colonnes**

CatÃ©gories : DÃ©mographie Â· CarriÃ¨re Â· RÃ©munÃ©ration Â· Satisfaction Â· Formation Â· Indicateurs de risque

<details>
<summary>Voir toutes les colonnes</summary>

**Profil** : `id`, `genre`, `age`, `statut_marital`, `ayant_enfants`, `niveau_education`

**Professionnel** : `poste`, `departement`, `domaine_etude`, `niveau_hierarchique_poste`, `nombre_experiences_precedentes`, `annee_experience_totale`, `annees_dans_l_entreprise`, `annees_dans_le_poste_actuel`, `annees_depuis_la_derniere_promotion`, `annes_sous_responsable_actuel`, `nombre_employee_sous_responsabilite`

**Travail** : `revenu_mensuel`, `heure_supplementaires`, `nombre_heures_travailless`, `distance_domicile_travail`, `distance_categorie`, `frequence_deplacement`

**Satisfaction** : `satisfaction_employee_environnement`, `satisfaction_employee_nature_travail`, `satisfaction_employee_equipe`, `satisfaction_employee_equilibre_pro_perso`, `satisfaction_moyenne`, `note_evaluation_precedente`, `note_evaluation_actuelle`

**DÃ©veloppement** : `nb_formations_suivies`, `nombre_participation_pee`

**Risques** : `parent_burnout`, `sous_paye_niveau_dept`, `augementation_salaire_precedente`
</details>

## Interface Streamlit

Interface web interactive avec 3 pages :
- **Explorer** : Liste des employÃ©s avec filtres
- **Recherche** : DÃ©tails par ID
- **Statistiques** : Visualisations interactives (Plotly)

Voir [streamlit_app/DOCUMENTATION.md](streamlit_app/DOCUMENTATION.md) pour plus de dÃ©tails.

## Structure du Projet

```
api-attrition/
â”œâ”€â”€ main.py                     # API FastAPI
â”œâ”€â”€ streamlit_launcher.py       # Launcher API + Interface
â”œâ”€â”€ database/                   # Config DB + modÃ¨les SQLAlchemy
â”œâ”€â”€ api/                        # SchÃ©mas Pydantic
â”œâ”€â”€ streamlit_app/              # Interface Streamlit
â”‚   â”œâ”€â”€ app.py                  # Page d'accueil
â”‚   â”œâ”€â”€ pages/                  # Pages multi-pages
â”‚   â””â”€â”€ utils/                  # Client API + composants UI
â””â”€â”€ data/                       # Dataset CSV (294 employÃ©s)
```

## ğŸš€ DÃ©ploiement sur Hugging Face Spaces

L'application est automatiquement dÃ©ployÃ©e sur HF Spaces via GitHub Actions.

### Configuration (premiÃ¨re fois)

1. **CrÃ©er un token Hugging Face**
   - Allez sur https://huggingface.co/settings/tokens
   - CrÃ©ez un token avec permission **Write**
   - Copiez le token (format: `hf_xxxxxxxxxxxxx`)

2. **Ajouter le token dans GitHub Secrets**
   - Allez dans Settings â†’ Secrets and variables â†’ Actions
   - CrÃ©ez un secret `HF_TOKEN` avec votre token

3. **Pusher sur main**
   ```bash
   git push origin main
   ```

Le dÃ©ploiement se fait automatiquement ! ğŸ‰

**URL du Space** : https://huggingface.co/spaces/ppluton/api_technova

Voir [.github/DEPLOYMENT.md](.github/DEPLOYMENT.md) pour la documentation complÃ¨te.

### Base de donnÃ©es : PostgreSQL vs SQLite

L'application supporte deux types de bases de donnÃ©es :

**PostgreSQL** (dÃ©veloppement local avec Docker) :
```bash
export DB_TYPE=postgres  # ou ne rien dÃ©finir avec Docker
docker-compose up -d
uv run database/import_data.py
```

**SQLite** (production HF Spaces / dÃ©veloppement simple) :
```bash
export DB_TYPE=sqlite  # par dÃ©faut
uv run database/migrate_to_sqlite.py  # GÃ©nÃ¨re database.db
```

La base SQLite (`database.db`) est automatiquement crÃ©Ã©e et incluse dans le repo pour HF Spaces.

## Roadmap

- [x] ~~DÃ©ploiement cloud (Hugging Face Spaces)~~ âœ…
- [x] ~~Support SQLite pour dÃ©ploiement cloud~~ âœ…
- [x] ~~CI/CD automatique vers HF Spaces~~ âœ…
- [ ] ModÃ¨le ML pour prÃ©diction d'attrition
- [ ] Endpoint POST /predict
- [ ] Filtres avancÃ©s sur GET /employees
- [ ] Authentification API (JWT)

## Tests & CI/CD

### Lancer les tests

```bash
# Lancer tous les tests (13 tests)
pytest tests/

# Tests unitaires (8 tests)
pytest tests/unit -v

# Tests fonctionnels (5 tests)
pytest tests/functional -v

# Avec coverage (rapport dans le terminal)
pytest tests/ --cov=. --cov-report=term-missing
```

### Rapports de couverture

**Local** :
```bash
# GÃ©nÃ©rer rapport HTML
pytest tests/ --cov=. --cov-report=html

# Ouvrir le rapport
open htmlcov/index.html  # macOS
```

**CI/CD** :
- Badge de couverture visible en haut du README
- Rapport dÃ©taillÃ© sur [Codecov](https://codecov.io/gh/Pltn-1321/api-attrition)
- Rapport HTML tÃ©lÃ©chargeable dans les artifacts GitHub Actions

### Pipeline automatique

Le workflow CI/CD (`ci-cd.yml`) s'exÃ©cute automatiquement :
- **Sur push/PR** : Lint + Tests + Coverage
- **Sur push `main`** : + DÃ©ploiement vers Hugging Face Spaces

**Documentation complÃ¨te** : [CI-CD.md](CI-CD.md) - Architecture, stratÃ©gie de tests, pipeline GitHub Actions

## FAQ & Troubleshooting

### â“ Pourquoi l'application utilise `localhost:8000` en production ?

**RÃ©ponse** : C'est normal et correct ! Sur Hugging Face Spaces, FastAPI et Streamlit s'exÃ©cutent dans le **mÃªme conteneur Docker**. Streamlit communique avec FastAPI via `localhost:8000` en interne. Seul le port 7860 (Streamlit) est exposÃ© Ã  Internet.

```
Utilisateur â†’ HF Spaces (port 7860) â†’ Streamlit â†’ localhost:8000 â†’ FastAPI
```

### âš ï¸ Erreur 503: Service Unavailable

**SymptÃ´me** : "503 Server Error: Service Unavailable for url: http://localhost:8000/..."

**Causes possibles** :
1. L'API FastAPI n'a pas encore terminÃ© son dÃ©marrage
2. L'API a crashÃ© au dÃ©marrage
3. Les ports ne sont pas correctement configurÃ©s

**Solutions** :

1. **Attendre et rÃ©essayer** (le plus courant)
   - L'application attend automatiquement jusqu'Ã  30 secondes que l'API soit prÃªte
   - Cliquez sur le bouton "ğŸ”„ RÃ©essayer la connexion" dans l'interface

2. **VÃ©rifier les logs** (Hugging Face Spaces)
   - Allez dans l'onglet "Logs" de votre Space
   - VÃ©rifiez que les deux messages apparaissent :
     ```
     âœ… API dÃ©marrÃ©e sur http://localhost:8000
     âœ… API est prÃªte ! (dÃ©marrage en Xs)
     ```

3. **VÃ©rifier la configuration locale**
   ```bash
   # VÃ©rifier que les ports sont libres
   lsof -i:8000  # Doit Ãªtre vide
   lsof -i:8501  # Doit Ãªtre vide

   # RedÃ©marrer proprement
   lsof -ti:8000,8501 | xargs kill -9
   uv run streamlit_launcher.py
   ```

### ğŸ”§ Tests de diagnostic

```bash
# VÃ©rifier la configuration
pytest tests/unit/test_config.py -v

# VÃ©rifier la disponibilitÃ© de l'API
pytest tests/functional/test_api_availability.py -v

# VÃ©rifier Dockerfile
grep "ENV API_URL" Dockerfile
# Devrait afficher: ENV API_URL=http://localhost:8000
```

### ğŸ› L'API dÃ©marre trop lentement

**Solution** : Le `streamlit_launcher.py` attend dÃ©sormais jusqu'Ã  **30 secondes** pour que l'API dÃ©marre. Si votre machine est lente :

```python
# Dans streamlit_launcher.py (ligne 139)
api_ready = wait_for_api(API_PORT, max_retries=30, retry_interval=1)
# Vous pouvez augmenter max_retries si nÃ©cessaire
```

### ğŸ“Š Les tests de couverture Ã©chouent

**ProblÃ¨me** : `FAIL Required test coverage of 60% not reached`

**Solution** : Assurez-vous d'exÃ©cuter TOUS les tests ensemble :
```bash
# âœ… Correct - tous les tests
pytest tests/ --cov=utils.api_client --cov=api --cov=database --cov=main

# âŒ Incorrect - tests partiels
pytest tests/unit/test_ml_model.py --cov=main  # Couverture trop faible
```

### ğŸ”„ DÃ©ploiement automatique ne fonctionne pas

**Checklist** :
1. âœ… Le secret `HF_TOKEN` est dÃ©fini dans GitHub Secrets
2. âœ… Le push est sur la branche `main`
3. âœ… Tous les tests passent (voir GitHub Actions)
4. âœ… Le fichier `Dockerfile` est prÃ©sent et valide
5. âœ… L'URL du Space est correcte dans `.github/workflows/ci-cd.yml`

### ğŸ“š Plus d'aide

- **Documentation technique** : [CLAUDE.md](CLAUDE.md)
- **CI/CD dÃ©taillÃ©e** : [CI-CD.md](CI-CD.md)
- **Issues GitHub** : https://github.com/Pltn-1321/api-attrition/issues
