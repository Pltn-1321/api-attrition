---
title: API Technova - Gestion RH & Attrition
emoji: ðŸ‘¥
colorFrom: blue
colorTo: purple
sdk: docker
app_port: 7860
pinned: false
license: mit
tags:
  - rh
  - data-science
  - analytics
  - fastapi
  - streamlit
---

# API Attrition

[![codecov](https://codecov.io/gh/Pltn-1321/api-attrition/branch/main/graph/badge.svg)](https://codecov.io/gh/Pltn-1321/api-attrition)
[![CI/CD](https://github.com/Pltn-1321/api-attrition/workflows/CI/CD%20Pipeline/badge.svg)](https://github.com/Pltn-1321/api-attrition/actions)

API FastAPI pour la prÃ©diction d'attrition des employÃ©s avec machine learning.

**Stack** : FastAPI Â· PostgreSQL/SQLite Â· SQLAlchemy Â· Streamlit Â· Scikit-learn Â· Docker

**DÃ©ploiement** : GitHub Actions Â· Hugging Face Spaces Â· CI/CD

## DÃ©marrage Rapide

```bash
# 1. Cloner et installer
git clone git@github.com:Pltn-1321/api-attrition.git
cd api-attrition
uv add pandas sqlalchemy psycopg2-binary fastapi uvicorn streamlit

# 2. DÃ©marrer PostgreSQL
docker-compose up -d

# 3. Importer les donnÃ©es (294 employÃ©s)
uv run database/import_data.py

# 4. Lancer l'application (API + Interface)
uv run streamlit_launcher.py
```

**URLs** :
- Interface : http://localhost:8501
- API : http://localhost:8000
- Docs API : http://localhost:8000/docs

## ðŸ§ª Tests

### Structure des Tests
```
tests/
â”œâ”€â”€ unit/                    # Tests unitaires (logique isolÃ©e)
â”‚   â””â”€â”€ test_ml_model.py    # Tests modÃ¨le ML et calculs
â”œâ”€â”€ functional/             # Tests fonctionnels (scÃ©narios complets)
â”‚   â””â”€â”€ test_prediction_api.py  # Tests endpoint /predict
â”œâ”€â”€ conftest.py            # Fixtures partagÃ©es
â””â”€â”€ fixtures/              # DonnÃ©es de test
```

### ExÃ©cuter les Tests

```bash
# Tous les tests avec couverture
uv run pytest

# Tests unitaires uniquement
uv run pytest tests/unit/ -v

# Tests fonctionnels uniquement
uv run pytest tests/functional/ -v

# Tests ML spÃ©cifiques
uv run pytest tests/unit/test_ml_model.py -v --ml

# Tests API
uv run pytest tests/functional/test_prediction_api.py -v --api

# Rapport de couverture HTML
uv run pytest --cov=utils --cov=api --cov-report=html
```

### Types de Tests

#### ðŸ¤– Tests Machine Learning
- **Chargement du modÃ¨le** : VÃ©rifie que `attrition_model.joblib` se charge correctement
- **PrÃ©dictions** : Teste la cohÃ©rence des rÃ©sultats (0/1, probabilitÃ©s)
- **Cas limites** : Gestion des valeurs extrÃªmes et donnÃ©es manquantes
- **Performance** : Temps de rÃ©ponse < 100ms par prÃ©diction

#### ðŸ”Œ Tests API
- **Endpoint `/predict`** : Validation des schÃ©mas et rÃ©ponses
- **Gestion d'erreurs** : ModÃ¨le indisponible, donnÃ©es invalides
- **Concurrence** : RequÃªtes simultanÃ©es sans conflit
- **Robustesse** : CaractÃ¨res spÃ©ciaux, types de donnÃ©es

#### ðŸ“Š Couverture Cible
- **API endpoints** : 100%
- **Logique mÃ©tier** : 95%
- **ModÃ¨le ML** : 90%
- **Components UI** : 85%

### Fixtures de Test

- `sample_employee_data_low_risk` : Profil employÃ© faible risque
- `sample_employee_data_high_risk` : Profil employÃ© haut risque
- `sample_employee_data_medium_risk` : Profil employÃ© risque moyen
- `ml_model` : ModÃ¨le ML chargÃ© pour les tests

### CI/CD Integration

Les tests s'exÃ©cutent automatiquement sur :
- **Push** vers `main`/`dev`
- **Pull Requests**
- **Workflow manuel**

Le pipeline gÃ©nÃ¨re :
- Rapports de couverture Codecov
- Artefacts HTML de couverture
- Validation qualitÃ© (Ruff, Black)

## Commandes

### Lancer l'application

```bash
# Tout en un (recommandÃ©) - Lance API + Interface
uv run streamlit_launcher.py

# Ou avec le script interactif
./start.sh

# Ou sÃ©parÃ©ment
uv run uvicorn main:app --reload --port 8000  # API seulement
uv run streamlit run app.py  # Interface seulement
```

### ArrÃªter l'application

```bash
# Avec Ctrl+C si lancÃ© avec streamlit_launcher.py
# Ou tuer les processus
lsof -ti:8000,8501 | xargs kill -9
```

### Commandes PostgreSQL

```bash
docker-compose up -d              # DÃ©marrer
docker-compose down               # ArrÃªter
docker logs attrition_db          # Voir les logs

# AccÃ©der Ã  psql
docker exec -it attrition_db psql -U attrition_user -d attrition_db
```

## API Endpoints

| Endpoint | MÃ©thode | Description |
|----------|---------|-------------|
| `/` | GET | Informations de l'API |
| `/health` | GET | VÃ©rification de santÃ© (API + DB) |
| `/employees` | GET | Liste des employÃ©s (pagination : `?skip=0&limit=100`) |
| `/employees/{id}` | GET | DÃ©tails d'un employÃ© |

**Exemples** :
```bash
curl http://localhost:8000/health
curl http://localhost:8000/employees?limit=10
curl http://localhost:8000/employees/1
```

Documentation interactive : http://localhost:8000/docs

## DonnÃ©es

**294 employÃ©s Â· 34 colonnes**

CatÃ©gories : DÃ©mographie Â· CarriÃ¨re Â· RÃ©munÃ©ration Â· Satisfaction Â· Formation Â· Indicateurs de risque

<details>
<summary>Voir toutes les colonnes</summary>

**Profil** : `id`, `genre`, `age`, `statut_marital`, `ayant_enfants`, `niveau_education`

**Professionnel** : `poste`, `departement`, `domaine_etude`, `niveau_hierarchique_poste`, `nombre_experiences_precedentes`, `annee_experience_totale`, `annees_dans_l_entreprise`, `annees_dans_le_poste_actuel`, `annees_depuis_la_derniere_promotion`, `annes_sous_responsable_actuel`, `nombre_employee_sous_responsabilite`

**Travail** : `revenu_mensuel`, `heure_supplementaires`, `nombre_heures_travailless`, `distance_domicile_travail`, `distance_categorie`, `frequence_deplacement`

**Satisfaction** : `satisfaction_employee_environnement`, `satisfaction_employee_nature_travail`, `satisfaction_employee_equipe`, `satisfaction_employee_equilibre_pro_perso`, `satisfaction_moyenne`, `note_evaluation_precedente`, `note_evaluation_actuelle`

**DÃ©veloppement** : `nb_formations_suivies`, `nombre_participation_pee`

**Risques** : `parent_burnout`, `sous_paye_niveau_dept`, `augementation_salaire_precedente`
</details>

## Interface Streamlit

Interface web interactive avec 3 pages :
- **Explorer** : Liste des employÃ©s avec filtres
- **Recherche** : DÃ©tails par ID
- **Statistiques** : Visualisations interactives (Plotly)

Voir [streamlit_app/DOCUMENTATION.md](streamlit_app/DOCUMENTATION.md) pour plus de dÃ©tails.

## Structure du Projet

```
api-attrition/
â”œâ”€â”€ main.py                     # API FastAPI
â”œâ”€â”€ streamlit_launcher.py       # Launcher API + Interface
â”œâ”€â”€ database/                   # Config DB + modÃ¨les SQLAlchemy
â”œâ”€â”€ api/                        # SchÃ©mas Pydantic
â”œâ”€â”€ streamlit_app/              # Interface Streamlit
â”‚   â”œâ”€â”€ app.py                  # Page d'accueil
â”‚   â”œâ”€â”€ pages/                  # Pages multi-pages
â”‚   â””â”€â”€ utils/                  # Client API + composants UI
â””â”€â”€ data/                       # Dataset CSV (294 employÃ©s)
```

## ðŸš€ DÃ©ploiement sur Hugging Face Spaces

L'application est automatiquement dÃ©ployÃ©e sur HF Spaces via GitHub Actions.

### Configuration (premiÃ¨re fois)

1. **CrÃ©er un token Hugging Face**
   - Allez sur https://huggingface.co/settings/tokens
   - CrÃ©ez un token avec permission **Write**
   - Copiez le token (format: `hf_xxxxxxxxxxxxx`)

2. **Ajouter le token dans GitHub Secrets**
   - Allez dans Settings â†’ Secrets and variables â†’ Actions
   - CrÃ©ez un secret `HF_TOKEN` avec votre token

3. **Pusher sur main**
   ```bash
   git push origin main
   ```

Le dÃ©ploiement se fait automatiquement ! ðŸŽ‰

**URL du Space** : https://huggingface.co/spaces/ppluton/api_technova

Voir [.github/DEPLOYMENT.md](.github/DEPLOYMENT.md) pour la documentation complÃ¨te.

### Base de donnÃ©es : PostgreSQL vs SQLite

L'application supporte deux types de bases de donnÃ©es :

**PostgreSQL** (dÃ©veloppement local avec Docker) :
```bash
export DB_TYPE=postgres  # ou ne rien dÃ©finir avec Docker
docker-compose up -d
uv run database/import_data.py
```

**SQLite** (production HF Spaces / dÃ©veloppement simple) :
```bash
export DB_TYPE=sqlite  # par dÃ©faut
uv run database/migrate_to_sqlite.py  # GÃ©nÃ¨re database.db
```

La base SQLite (`database.db`) est automatiquement crÃ©Ã©e et incluse dans le repo pour HF Spaces.

## Roadmap

- [x] ~~DÃ©ploiement cloud (Hugging Face Spaces)~~ âœ…
- [x] ~~Support SQLite pour dÃ©ploiement cloud~~ âœ…
- [x] ~~CI/CD automatique vers HF Spaces~~ âœ…
- [ ] ModÃ¨le ML pour prÃ©diction d'attrition
- [ ] Endpoint POST /predict
- [ ] Filtres avancÃ©s sur GET /employees
- [ ] Authentification API (JWT)

## Tests & CI/CD

### Lancer les tests

```bash
# Lancer tous les tests (13 tests)
pytest tests/

# Tests unitaires (8 tests)
pytest tests/unit -v

# Tests fonctionnels (5 tests)
pytest tests/functional -v

# Avec coverage (rapport dans le terminal)
pytest tests/ --cov=. --cov-report=term-missing
```

### Rapports de couverture

**Local** :
```bash
# GÃ©nÃ©rer rapport HTML
pytest tests/ --cov=. --cov-report=html

# Ouvrir le rapport
open htmlcov/index.html  # macOS
```

**CI/CD** :
- Badge de couverture visible en haut du README
- Rapport dÃ©taillÃ© sur [Codecov](https://codecov.io/gh/Pltn-1321/api-attrition)
- Rapport HTML tÃ©lÃ©chargeable dans les artifacts GitHub Actions

### Pipeline automatique

Le workflow CI/CD (`ci-cd.yml`) s'exÃ©cute automatiquement :
- **Sur push/PR** : Lint + Tests + Coverage
- **Sur push `main`** : + DÃ©ploiement vers Hugging Face Spaces

**Documentation complÃ¨te** : [CI-CD.md](CI-CD.md) - Architecture, stratÃ©gie de tests, pipeline GitHub Actions
